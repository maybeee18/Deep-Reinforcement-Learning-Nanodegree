{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python-opengl is already the newest version (3.0.2-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:2.8.15-0ubuntu0.16.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "xvfb is already the newest version (2:1.18.4-0ubuntu0.8).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "x11-utils is already the newest version (7.7+3).\n",
      "x11-utils set to manually installed.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Collecting pyvirtualdisplay\n",
      "  Downloading https://files.pythonhosted.org/packages/69/ec/8221a07850d69fa3c57c02e526edd23d18c7c05d58ed103e3b19172757c1/PyVirtualDisplay-0.2.5-py2.py3-none-any.whl\n",
      "Collecting EasyProcess (from pyvirtualdisplay)\n",
      "  Downloading https://files.pythonhosted.org/packages/32/8f/88d636f1da22a3c573259e44cfefb46a117d3f9432e2c98b1ab4a21372ad/EasyProcess-0.2.10-py2.py3-none-any.whl\n",
      "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
      "Successfully installed EasyProcess-0.2.10 pyvirtualdisplay-0.2.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x400x24', ':1001'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '400x400x24', ':1001'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This part for required installations inside udacity VM\n",
    "!pip -q install ./python\n",
    "!apt install python-opengl\n",
    "!apt install ffmpeg\n",
    "!apt install xvfb\n",
    "!apt-get install x11-utils\n",
    "!pip install pyvirtualdisplay\n",
    "from pyvirtualdisplay import Display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-21 10:49:32--  https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4283 (4.2K) [text/plain]\n",
      "Saving to: ‘segment_tree.py.11’\n",
      "\n",
      "segment_tree.py.11  100%[===================>]   4.18K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-04-21 10:49:32 (41.8 MB/s) - ‘segment_tree.py.11’ saved [4283/4283]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# These parts are imports \n",
    "# also downloading segment_tree file structure\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "!wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [ 1.          0.          0.          0.          0.84408134  0.          0.\n",
      "  1.          0.          0.0748472   0.          1.          0.          0.\n",
      "  0.25755     1.          0.          0.          0.          0.74177343\n",
      "  0.          1.          0.          0.          0.25854847  0.          0.\n",
      "  1.          0.          0.09355672  0.          1.          0.          0.\n",
      "  0.31969345  0.          0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name=\"/data/Banana_Linux_NoVis/Banana.x86_64\")\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        self.ptr, self.size, = 0, 0\n",
    "        \n",
    "        # for N-step Learning\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        self.n_step = n_step\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # single step transition is not ready\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()\n",
    "        \n",
    "        # make a n-step transition\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.next_obs_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "            # for N-step Learning\n",
    "            indices=indices,\n",
    "        )\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # for N-step Learning\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],\n",
    "            next_obs=self.next_obs_buf[idxs],\n",
    "            acts=self.acts_buf[idxs],\n",
    "            rews=self.rews_buf[idxs],\n",
    "            done=self.done_buf[idxs],\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # info of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "\n",
    "        return rew, next_obs, done\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        alpha: float = 0.6,\n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        assert alpha >= 0\n",
    "        \n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # capacity must be positive and a power of 2.\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: int, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        \n",
    "        if transition:\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        \n",
    "        return transition\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        assert len(self) >= self.batch_size\n",
    "        assert beta > 0\n",
    "        \n",
    "        indices = self._sample_proportional()\n",
    "        \n",
    "        obs = self.obs_buf[indices]\n",
    "        next_obs = self.next_obs_buf[indices]\n",
    "        acts = self.acts_buf[indices]\n",
    "        rews = self.rews_buf[indices]\n",
    "        done = self.done_buf[indices]\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        \n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        assert len(indices) == len(priorities)\n",
    "\n",
    "        for idx, priority in zip(indices, priorities):\n",
    "            assert priority > 0\n",
    "            assert 0 <= idx < len(self)\n",
    "\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        indices = []\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        segment = p_total / self.batch_size\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "            upperbound = random.uniform(a, b)\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            indices.append(idx)\n",
    "            \n",
    "        return indices\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # get max weight\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        \n",
    "        # calculate weights\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        weight = weight / max_weight\n",
    "        \n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        std_init: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)\n",
    "        )\n",
    "\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))\n",
    "\n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        mu_range = 1 / math.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)\n",
    "        )\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)\n",
    "        )\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "\n",
    "        # outer product\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(epsilon_out)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        return F.linear(\n",
    "            x,\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        x = torch.FloatTensor(np.random.normal(loc=0.0, scale=1.0, size=size))\n",
    "\n",
    "        return x.sign().mul(x.abs().sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.support = support\n",
    "        self.out_dim = out_dim\n",
    "        self.atom_size = atom_size\n",
    "\n",
    "        # set common feature layer\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # set advantage layer\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)\n",
    "\n",
    "        # set value layer\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128)\n",
    "        self.value_layer = NoisyLinear(128, atom_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)\n",
    "        q = torch.sum(dist * self.support, dim=2)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        feature = self.feature_layer(x)\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))\n",
    "        \n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # for avoiding nans\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()\n",
    "        self.advantage_layer.reset_noise()\n",
    "        self.value_hidden_layer.reset_noise()\n",
    "        self.value_layer.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"/home/workspace/model1.pth\"\n",
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: UnityEnvironment,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "        model_file_name : str = None\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        \n",
    "        self.brain_name = env.brain_names[0]\n",
    "        self.brain = env.brains[self.brain_name]\n",
    "        # reset the environment\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "        # number of agents in the environment\n",
    "        print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "        # number of actions\n",
    "        action_size = brain.vector_action_space_size\n",
    "        print('Number of actions:', action_size)\n",
    "\n",
    "        # examine the state space \n",
    "        state = env_info.vector_observations[0]\n",
    "        print('States look like:', state)\n",
    "        state_size = len(state)\n",
    "        print('States have length:', state_size)\n",
    "        obs_dim = state_size\n",
    "        action_dim = action_size\n",
    "        \n",
    "        self.env = env\n",
    "        self.batch_size = batch_size\n",
    "        self.target_update = target_update\n",
    "        self.gamma = gamma\n",
    "        # NoisyNet: All attributes related to epsilon are removed\n",
    "        \n",
    "        # device: cpu / gpu\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)\n",
    "        \n",
    "        # PER\n",
    "        # memory for 1-step Learning\n",
    "        self.beta = beta\n",
    "        self.prior_eps = prior_eps\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha\n",
    "        )\n",
    "        \n",
    "        # memory for N-step Learning\n",
    "        self.use_n_step = True if n_step > 1 else False\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )\n",
    "            \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min\n",
    "        self.v_max = v_max\n",
    "        self.atom_size = atom_size\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        # networks: dqn, dqn_target\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)\n",
    "        if model_file_name != None:\n",
    "            self.dqn.load_state_dict(torch.load(model_file_name))\n",
    "\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "        self.dqn_target.eval()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())\n",
    "\n",
    "        # transition to store in memory\n",
    "        self.transition = list()\n",
    "        \n",
    "        # mode: train / test\n",
    "        self.is_test = False\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # NoisyNet: no epsilon greedy action selection\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        ).argmax()\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        \n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        return int(selected_action)\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        env_info = self.env.step(action)[brain_name]\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]  \n",
    "\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            \n",
    "            # N-step transition\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # 1-step transition\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "\n",
    "            # add a single step transition\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "    \n",
    "        return next_state, reward, done\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # PER needs beta to calculate weights\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)\n",
    "        indices = samples[\"indices\"]\n",
    "        \n",
    "        # 1-step Learning loss\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        \n",
    "        # PER: importance sampling before average\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        \n",
    "        # N-step Learning loss\n",
    "        # we are gonna combine 1-step loss and n-step loss so as to\n",
    "        # prevent high-variance. The original rainbow employs n-step loss only.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)\n",
    "            elementwise_loss += elementwise_loss_n_loss\n",
    "            \n",
    "            # PER: importance sampling before average\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # PER: update priorities\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()\n",
    "        new_priorities = loss_for_prior + self.prior_eps\n",
    "        self.memory.update_priorities(indices, new_priorities)\n",
    "        \n",
    "        # NoisyNet: reset noise\n",
    "        self.dqn.reset_noise()\n",
    "        self.dqn_target.reset_noise()\n",
    "\n",
    "        return loss.item()\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False\n",
    "        env_info = self.env.reset(train_mode=True)[self.brain_name]\n",
    "        state = env_info.vector_observations[0] \n",
    "        update_cnt = 0\n",
    "        losses = []\n",
    "        scores = []\n",
    "        score = 0\n",
    "\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            \n",
    "            # NoisyNet: removed decrease of epsilon\n",
    "            \n",
    "            # PER: increase beta\n",
    "            fraction = min(frame_idx / num_frames, 1.0)\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)\n",
    "\n",
    "            # if episode ends\n",
    "            if done:\n",
    "                env_info = self.env.reset(train_mode=True)[self.brain_name]\n",
    "                state = env_info.vector_observations[0] \n",
    "                scores.append(score)\n",
    "                score = 0\n",
    "\n",
    "            # if training is ready\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)\n",
    "                update_cnt += 1\n",
    "                \n",
    "                # if hard update is needed\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "\n",
    "            # plotting\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)\n",
    "                torch.save(self.dqn.state_dict(),SAVE_PATH)\n",
    "\n",
    "                \n",
    "        self.env.close()\n",
    "                \n",
    "    def test(self) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        self.is_test = True\n",
    "        \n",
    "        env_info = self.env.reset(train_mode=False)[self.brain_name]\n",
    "        state = env_info.vector_observations[0] \n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        while not done:\n",
    "            #self.env.render()\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done = self.step(action)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "        \n",
    "        print(\"score: \", score)\n",
    "        self.env.close()\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # for shortening the following lines\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        \n",
    "        # Categorical DQN algorithm\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Double DQN\n",
    "            next_action = self.dqn(next_state).argmax(1)\n",
    "            next_dist = self.dqn_target.dist(next_state)\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]\n",
    "\n",
    "            t_z = reward + (1 - done) * gamma * self.support\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)\n",
    "            b = (t_z - self.v_min) / delta_z\n",
    "            l = b.floor().long()\n",
    "            u = b.ceil().long()\n",
    "\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )\n",
    "\n",
    "        dist = self.dqn.dist(state)\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)\n",
    "\n",
    "        return elementwise_loss\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int, \n",
    "        scores: List[float], \n",
    "        losses: List[float],\n",
    "    ):\n",
    "        \"\"\"Plot the training progresses.\"\"\"\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(131)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n",
    "        plt.plot(scores)\n",
    "        plt.subplot(132)\n",
    "        plt.title('loss')\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [ 0.          1.          0.          0.          0.16895212  0.          1.\n",
      "  0.          0.          0.20073597  1.          0.          0.          0.\n",
      "  0.12865657  0.          1.          0.          0.          0.14938059\n",
      "  1.          0.          0.          0.          0.58185619  0.          1.\n",
      "  0.          0.          0.16089135  0.          1.          0.          0.\n",
      "  0.31775284  0.          0.        ]\n",
      "States have length: 37\n",
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [ 1.          0.          0.          0.          0.43657523  1.          0.\n",
      "  0.          0.          0.19398789  1.          0.          0.          0.\n",
      "  0.47860974  0.          0.          1.          0.          0.52109712\n",
      "  0.          0.          1.          0.          0.38285938  1.          0.\n",
      "  0.          0.          0.10405888  1.          0.          0.          0.\n",
      "  0.37148568  0.          0.        ]\n",
      "States have length: 37\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 777\n",
    "\n",
    "def seed_torch(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "seed_torch(seed)\n",
    "#env.seed(seed)itignore\n",
    "\n",
    "# parameters\n",
    "num_frames = 250000\n",
    "memory_size = 1000\n",
    "batch_size = 32\n",
    "target_update = 100\n",
    "\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update,model_file_name = SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ba01c6a58>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-90cf5cdc5c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-f2b0f273a771>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_frames, plotting_interval)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# if training is ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mupdate_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f2b0f273a771>\u001b[0m in \u001b[0;36mupdate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_frames = 1000000\n",
    "\n",
    "agent.train(num_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:  14.0\n"
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agent while it is training.  However, **_after training the agent_**, you can download the saved model weights to watch the agent on your own machine! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
